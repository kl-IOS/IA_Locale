---
title: "Cr√©ez votre IA Locale"
subtitle: "Le Guide Complet de A √† Z pour les Non-Techniciens"
author: "Guide IA Locale"
date: "Octobre 2025"
theme: "Madrid"
colortheme: "seahorse"
fonttheme: "structurebold"
aspectratio: 169
---

# Cr√©ez votre IA Locale üöÄ

**Le Guide Complet de A √† Z**

*Pour les non-techniciens*

::: notes
Cette pr√©sentation s'adresse √† un public non-technique souhaitant comprendre et cr√©er une IA locale.
Le ton est accessible, friendly et encourageant.
Dur√©e estim√©e : 20-30 minutes.
:::

---

# Qu'est-ce qu'une IA locale ? ü§î

Une IA locale fonctionne **enti√®rement sur votre ordinateur**, sans connexion Internet.

:::::::::::::: {.columns}
::: {.column width="33%"}
## üîí Confidentialit√©

Vos donn√©es restent **chez vous**

- Aucune transmission externe
- Contr√¥le total
- Z√©ro fuite de donn√©es
:::

::: {.column width="33%"}
## üéÆ Contr√¥le complet

Vous ma√Ætrisez **tout le syst√®me**

- Personnalisation totale
- Pas de limitations
- Votre infrastructure
:::

::: {.column width="33%"}
## üí∏ Sans abonnement

**Pas de co√ªts r√©currents**

- Investissement unique
- Pas de surprise
- √âconomies long terme
:::
::::::::::::::

::: notes
Insister sur les 3 piliers : confidentialit√©, contr√¥le, √©conomies.
Exemples concrets : documents d'entreprise sensibles, donn√©es m√©dicales, informations financi√®res.
:::

---

# De quoi avez-vous besoin ? üíª

:::::::::::::: {.columns}
::: {.column width="50%"}
## Mat√©riel

‚úÖ **Ordinateur moderne**
- Windows, Mac ou Linux
- 16 √† 32 Go de RAM
- Carte graphique (id√©alement NVIDIA)
- SSD 256 Go minimum

üí° *Pas besoin de super-ordinateur !*
:::

::: {.column width="50%"}
## Logiciels

‚úÖ **Outils gratuits et open-source**
- Python (langage de programmation)
- Ollama ou LM Studio (IA locale)
- Biblioth√®ques sp√©cialis√©es

üí° *Tout est gratuit et t√©l√©chargeable !*
:::
::::::::::::::

::: notes
Rassurer l'audience : pas besoin de mat√©riel hors de prix.
Un bon PC gaming ou MacBook Pro r√©cent suffit amplement.
Tous les logiciels mentionn√©s sont gratuits et open-source.
:::

---

# Les 5 grandes √©tapes üó∫Ô∏è

```mermaid
graph LR
    A[1Ô∏è‚É£ D√©finir<br/>votre besoin] --> B[2Ô∏è‚É£ Pr√©parer<br/>vos donn√©es]
    B --> C[3Ô∏è‚É£ Choisir la<br/>bonne m√©thode]
    C --> D[4Ô∏è‚É£ Installer<br/>et configurer]
    D --> E[5Ô∏è‚É£ Tester<br/>et utiliser !]

    style A fill:#5EA8A7,color:#fff
    style B fill:#5EA8A7,color:#fff
    style C fill:#5EA8A7,color:#fff
    style D fill:#5EA8A7,color:#fff
    style E fill:#FE4447,color:#fff
```

::: notes
Vue d'ensemble du processus complet.
Montrer que c'est structur√© et progressif.
La derni√®re √©tape (test et utilisation) est mise en avant (couleur diff√©rente).
:::

---

# √âtape 1 : D√©finir votre besoin üéØ

**Posez-vous ces questions :**

:::::::::::::: {.columns}
::: {.column width="33%"}
### ‚ùì Que voulez-vous faire ?

- R√©pondre √† des questions
- R√©sumer des documents
- Analyser du texte
- G√©n√©rer du contenu
:::

::: {.column width="33%"}
### üìÅ Quelles donn√©es avez-vous ?

- Documents PDF, Word
- Notes personnelles
- Emails archiv√©s
- Historique YouTube
:::

::: {.column width="33%"}
### ‚ö° Vos contraintes ?

- Vitesse n√©cessaire
- Niveau de confidentialit√©
- Budget mat√©riel
- Complexit√© acceptable
:::
::::::::::::::

::: notes
Importance de bien d√©finir le besoin avant de se lancer.
Exemples concrets :
- Assistant pour chercher dans sa documentation personnelle
- R√©sumeur automatique d'articles de veille
- Chatbot pour r√©pondre sur ses notes de cours
:::

---

# √âtape 2 : Pr√©parer vos donn√©es üìä

:::::::::::::: {.columns}
::: {.column width="50%"}
## Sources possibles

**üìÑ Documents**
- PDF, Word, PowerPoint
- Fichiers texte

**üìù Notes**
- Markdown, Notion
- Obsidian, Evernote
:::

::: {.column width="50%"}
## Organisation n√©cessaire

**1. Nettoyer**
Supprimer doublons, corriger erreurs

**2. Prot√©ger**
Masquer infos personnelles

**3. D√©couper**
Diviser longs documents

**4. Enrichir**
Ajouter m√©tadonn√©es
:::
::::::::::::::

::: notes
Insister sur l'importance de la qualit√© des donn√©es.
"Garbage in, garbage out" : une IA nourrie de mauvaises donn√©es donnera de mauvais r√©sultats.
Anonymisation : exemple avec RGPD en entreprise.
:::

---

# √âtape 3 : RAG et Fine-tuning ‚öñÔ∏è

:::::::::::::: {.columns}
::: {.column width="50%"}
## RAG üîçüìù
**Recherche + G√©n√©ration**

‚úÖ **Avantages**
- Rapide √† mettre en place
- Id√©al pour documents
- **Recommand√© pour d√©buter**
- Pas d'entra√Ænement

üí° **Fonctionnement**
L'IA cherche dans vos documents puis g√©n√®re une r√©ponse

```mermaid
graph LR
    A[üìö Documents] --> B[üî¢ Vecteurs]
    B --> C[üíæ Base vectorielle]
    D[‚ùì Question] --> E[üîç Recherche]
    C --> E
    E --> F[ü§ñ IA]
    F --> G[‚úÖ R√©ponse]

    style A fill:#5EA8A7,color:#fff
    style G fill:#FE4447,color:#fff
```
:::

::: {.column width="50%"}
## Fine-tuning üéì
**Entra√Ænement personnalis√©**

‚úÖ **Avantages**
- Plus de contr√¥le
- Style personnalis√©
- Connaissances int√©gr√©es

‚ö†Ô∏è **Mais...**
- **Plus technique**
- N√©cessite beaucoup d'exemples
- Temps d'entra√Ænement

**√âtapes simples du RAG :**

1. Vos documents ‚Üí vecteurs
2. Recherche passages pertinents
3. IA formule la r√©ponse
:::
::::::::::::::

**Notre recommandation : Commencez par RAG !** üéØ

::: notes
RAG est l'approche la plus accessible pour d√©buter.
Fine-tuning pour plus tard, quand on a de l'exp√©rience.
Analogie : RAG = livre ouvert pendant l'exam, Fine-tuning = apprendre par c≈ìur
:::

---

# √âtape 4 : Installation compl√®te üõ†Ô∏è

:::::::::::::: {.columns}
::: {.column width="50%"}
## Outil principal : **Ollama** ‚≠ê

‚úÖ **Pourquoi Ollama ?**
- Interface **tr√®s simple**
- Installation en 2 minutes
- Windows, Mac, Linux
- Gratuit et open-source

### Installation Ollama

```bash
# Linux / macOS
curl -fsSL ollama.com/install.sh | sh

# Windows
# T√©l√©charger depuis ollama.com
```

### T√©l√©charger un mod√®le

```bash
ollama pull llama3.1:8b
```
:::

::: {.column width="50%"}
## Python et d√©pendances üêç

### Installer Python

**Windows**
1. T√©l√©charger python.org
2. Cocher "Add to PATH" ‚úÖ
3. V√©rifier : `python --version`

**Mac / Linux**
```bash
# Mac (Homebrew)
brew install python@3.11

# Linux (Ubuntu/Debian)
sudo apt install python3.11
```

### Biblioth√®ques n√©cessaires

```bash
# Cr√©er environnement virtuel
python -m venv mon_ia_locale
source mon_ia_locale/bin/activate

# Installer biblioth√®ques
pip install langchain chromadb \
  sentence-transformers ollama
```
:::
::::::::::::::

::: notes
Ollama est vraiment la solution la plus simple.
Montrer qu'en 2 commandes on peut avoir une IA fonctionnelle.
Tous les outils sont gratuits, insister l√†-dessus.
:::

---

# V√©rification et choix du mod√®le ‚úÖ

:::::::::::::: {.columns}
::: {.column width="50%"}
## Test rapide d'installation

```python
import ollama
from langchain_community.embeddings \
  import HuggingFaceEmbeddings

# Test 1 : Ollama
print("Test Ollama...")
response = ollama.chat(
  model='llama3.1:8b',
  messages=[{
    'role': 'user',
    'content': 'Bonjour !'
  }]
)
print(f"‚úÖ Ollama OK")

# Test 2 : Embeddings
embeddings = HuggingFaceEmbeddings()
test_vec = embeddings.embed_query("Test")
print(f"‚úÖ Embeddings : {len(test_vec)}D")

print("üéâ Tout fonctionne !")
```
:::

::: {.column width="50%"}
## Choisir le bon mod√®le

| Mod√®le | Taille | RAM | Qualit√© |
|--------|--------|-----|---------|
| **Llama 3.1 8B** | 4.7 GB | 8 GB | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Mistral 7B** | 4.1 GB | 8 GB | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Phi-3 Mini** | 2.3 GB | 4 GB | ‚≠ê‚≠ê‚≠ê |
| **Llama 13B** | 7.4 GB | 16 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

**Recommand√© d√©butant : Llama 3.1 8B**

### Config mat√©rielle recommand√©e

**Budget** (500-800‚Ç¨) : i5, 16GB RAM, RTX 3060
**Optimal** (1200-1800‚Ç¨) : i7, 32GB RAM, RTX 4070
**Pro** (3000‚Ç¨+) : i9, 64GB RAM, RTX 4090
:::
::::::::::::::

::: notes
Script de validation pour rassurer que tout est bien install√©.
Tableau clair pour aider au choix du mod√®le.
:::

---

# √âtape 5 : Cr√©er votre syst√®me RAG ! üé¨

**Processus en 5 sous-√©tapes**

1Ô∏è‚É£ Installer Ollama
2Ô∏è‚É£ T√©l√©charger un mod√®le (ex: Llama 3.1)
3Ô∏è‚É£ Indexer vos documents (Python + Chroma)
4Ô∏è‚É£ Cr√©er syst√®me Q&R (LangChain)
5Ô∏è‚É£ Tester et affiner !

### Script RAG complet (30 lignes)

```python
from langchain_community.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.llms import Ollama
from langchain.chains import RetrievalQA

# 1. Charger documents
loader = DirectoryLoader("mes_documents/", glob="**/*.txt")
documents = loader.load()

# 2. D√©couper en morceaux
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = text_splitter.split_documents(documents)

# 3. Cr√©er embeddings
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2")

# 4. Cr√©er base vectorielle
vectorstore = Chroma.from_documents(chunks, embeddings)

# 5. Connecter Ollama
llm = Ollama(model="llama3.1:8b")

# 6. Cr√©er syst√®me RAG
qa_chain = RetrievalQA.from_chain_type(
    llm=llm, retriever=vectorstore.as_retriever(search_kwargs={"k": 3})
)

# 7. Poser questions !
reponse = qa_chain.invoke({"query": "Qu'est-ce que le RAG ?"})
print(reponse['result'])
```

::: notes
Processus en 5 √©tapes simples et logiques.
Code complet fonctionnel en 30 lignes.
Total : un week-end pour avoir un syst√®me fonctionnel.
:::

---

# Exemple concret : Assistant de cours üéØ

**Situation** : 50 PDFs de cours universitaires

### √âtapes

1. Cr√©er dossier avec vos PDFs
2. Lancer script RAG
3. Attendre 2-5 minutes (indexation)
4. Poser vos questions !

### Questions exemples

```python
qa_chain.invoke({
  "query": "R√©sume le chapitre sur les r√©seaux de neurones"
})
qa_chain.invoke({
  "query": "Diff√©rence entre CNN et RNN ?"
})
```

### R√©sultat

‚úÖ R√©ponses **pr√©cises** bas√©es sur vos documents
‚úÖ **Sources cit√©es** (quel PDF, quelle page)
‚úÖ Temps de r√©ponse : **1-3 secondes**
‚úÖ √âconomie de temps : **-82%** (45min ‚Üí 8min)

::: notes
Exemple concret et relatable pour √©tudiants.
Montrer la valeur imm√©diate : gagner du temps dans les r√©visions.
:::

---

# Probl√®mes courants & Optimisations üîß

:::::::::::::: {.columns}
::: {.column width="50%"}
## ‚ùå Probl√®mes fr√©quents

**"Ollama not found"**
‚Üí Red√©marrer terminal ou ajouter au PATH

**"Out of memory"**
‚Üí Utiliser mod√®le plus petit (Phi-3)
‚Üí Fermer autres applications

**R√©ponses lentes (>10s)**
‚Üí V√©rifier GPU : `nvidia-smi`
‚Üí Installer CUDA toolkit

**R√©ponses impr√©cises**
‚Üí Nettoyer documents (OCR)
‚Üí Ajuster `chunk_size` (300/500/1000)
:::

::: {.column width="50%"}
## üöÄ 5 astuces d'optimisation

**1. Choisir le bon mod√®le**
- Llama 3.1 8B : √©quilibr√©
- Mistral 7B : excellent fran√ßais

**2. Optimiser chunking**
```python
chunk_size=500  # √âquilibr√© ‚úÖ
```

**3. Augmenter k (documents)**
```python
search_kwargs={"k": 5}
```

**4. Utiliser le cache**
```python
vectorstore = Chroma(
  persist_directory="./chroma_db"
)
```

**5. Ajuster temp√©rature**
```python
# Factuel
temperature=0.1
# Cr√©atif
temperature=0.7
```
:::
::::::::::::::

::: notes
Anticiper les probl√®mes courants pour rassurer.
Solutions concr√®tes et test√©es.
:::

---

# Avantages, limites et cas d'usage ‚öñÔ∏è

:::::::::::::: {.columns}
::: {.column width="50%"}
## ‚úÖ Avantages

**Confidentialit√© maximale**
- Donn√©es sous contr√¥le
- Aucune fuite

**Pas de frais r√©currents**
- Investissement unique
- Pas d'abonnement

**Personnalisation totale**
- Adapt√© √† vos besoins
- Aucune limite

## ‚ö†Ô∏è √Ä consid√©rer

**Investissement mat√©riel**
- PC performant : 500-2000‚Ç¨

**Courbe d'apprentissage**
- Quelques heures/jours

**Maintenance**
- Mises √† jour manuelles
:::

::: {.column width="50%"}
## üíº Cas d'usage concrets

**üè¢ Entreprise**
- Documentation interne
- Analyse contrats
- Support client L1

**üë®‚Äçüéì √âducation**
- Assistant r√©visions
- R√©sum√© de cours
- Q&A notes de lecture

**üè• Sant√©**
- Dossiers m√©dicaux
- Anonymisation donn√©es
- Assistant protocoles

**üî¨ Recherche**
- Analyse litt√©rature
- Veille scientifique

**Tous b√©n√©ficient de la confidentialit√© !** üîí
:::
::::::::::::::

**Verdict : Les avantages d√©passent les inconv√©nients !** üéâ

::: notes
√ätre honn√™te sur les limites mais positif sur le bilan global.
Comparaison cloud : ChatGPT Plus = 240$/an.
:::

---

# Comparaison Local vs Cloud ‚òÅÔ∏è

| Crit√®re | IA Locale üè† | IA Cloud ‚òÅÔ∏è |
|---------|-------------|------------|
| **Confidentialit√©** | ‚úÖ Totale | ‚ùå Partielle |
| **Co√ªt mensuel** | ‚úÖ 0‚Ç¨ | ‚ùå 20-100‚Ç¨ |
| **Co√ªt initial** | ‚ö†Ô∏è 500-2000‚Ç¨ | ‚úÖ 0‚Ç¨ |
| **Performance** | ‚ö†Ô∏è Selon mat√©riel | ‚úÖ Tr√®s √©lev√©e |
| **Personnalisation** | ‚úÖ Totale | ‚ùå Limit√©e |
| **Hors ligne** | ‚úÖ Oui | ‚ùå Non |
| **Complexit√©** | ‚ö†Ô∏è Moyenne | ‚úÖ Simple |

**Quand choisir le local ?**

‚úÖ Donn√©es sensibles (entreprise, sant√©, finance)
‚úÖ Usage intensif (amortissement rapide)
‚úÖ Besoin de personnalisation
‚úÖ Pas de connexion Internet fiable

::: notes
Tableau comparatif honn√™te.
Calcul d'amortissement : ChatGPT Plus √† 20$/mois = 720$ sur 3 ans.
Un PC avec GPU RTX 3060 √† 1000‚Ç¨ est amorti en moins de 2 ans.
:::

---

# Ressources et prochaines √©tapes üìö

:::::::::::::: {.columns}
::: {.column width="50%"}
## Documentation & Tutoriels

üìñ **Guide technique d√©taill√©** (PDF)
üé• **Tutoriels vid√©o** : Ollama, LangChain
üíª **Code d'exemple** : scripts Python

## Communaut√©s

- **Reddit r/LocalLLaMA** : entraide
- **Discord LangChain** : support technique
- **Hugging Face Forums** : questions mod√®les

## Outils

- **Ollama** : ollama.com
- **LM Studio** : lmstudio.ai
- **Hugging Face** : huggingface.co
:::

::: {.column width="50%"}
## üöÄ Prochaines √©tapes

**Week-end 1**
1. Installer Ollama (10 min)
2. T√©l√©charger Llama 3.1 (15 min)
3. Tester en ligne de commande (30 min)

**Semaine 1**
4. Installer Python (1h)
5. Pr√©parer donn√©es (2-4h)
6. Cr√©er premier RAG (3-5h)

**Roadmap Mois 1**
- S1 : Installation et tests
- S2 : RAG basique fonctionnel
- S3 : Optimisation
- S4 : Production

üìñ **Consultez le guide technique !**
:::
::::::::::::::

::: notes
Fournir ressources concr√®tes pour continuer.
Communaut√© active et bienveillante.
Planning r√©aliste : week-end pour d√©marrer, 1 mois pour syst√®me robuste.
:::

---

# FAQ & Glossaire üìñ‚ùì

:::::::::::::: {.columns}
::: {.column width="50%"}
## Questions Fr√©quentes

**Quel budget pr√©voir ?**
Minimum 500‚Ç¨, optimal 1500-2000‚Ç¨

**Temps pour √™tre op√©rationnel ?**
Week-end pour test, 1-2 semaines complet

**Faut-il √™tre d√©veloppeur ?**
Non, bases Python suffisent (quelques jours)

**Quelle taille de mod√®le ?**
D√©butant : 7-8B (Llama, Mistral)
Avanc√© : 13B avec bon GPU

**Plusieurs mod√®les possibles ?**
Oui ! Ollama permet de basculer facilement

**Donn√©es vraiment en local ?**
Oui, 100% local avec Ollama/llama.cpp
:::

::: {.column width="50%"}
## Glossaire

**IA Locale**
IA sur votre ordinateur sans Internet

**RAG**
Recherche dans documents pour r√©pondre

**LLM**
Grand Mod√®le de Langage, "cerveau" de l'IA

**Fine-tuning**
Entra√Æner l'IA pour style sp√©cifique

**Embeddings**
Repr√©sentation math√©matique du texte

**Ollama**
Outil simple pour IA locales

**Chunking**
D√©couper documents en morceaux

**Anonymisation**
Supprimer infos personnelles
:::
::::::::::::::

::: notes
R√©ponses concises aux questions fr√©quentes.
D√©finitions vulgaris√©es, accessibles √† tous.
:::

---

# Conclusion : Lancez-vous ! üéâ

## Ce que vous avez appris

‚úÖ Qu'est-ce qu'une IA locale et pourquoi c'est utile
‚úÖ Le mat√©riel et les logiciels n√©cessaires
‚úÖ Les 5 grandes √©tapes pour cr√©er votre IA
‚úÖ La diff√©rence entre RAG et fine-tuning
‚úÖ Comment d√©marrer concr√®tement

## Votre plan d'action

1. **Ce soir** : t√©l√©charger Ollama et tester un mod√®le
2. **Ce week-end** : pr√©parer vos premi√®res donn√©es
3. **Semaine prochaine** : cr√©er votre premier syst√®me RAG
4. **Dans 1 mois** : syst√®me complet en production !

**üöÄ Vous avez tout ce qu'il faut pour r√©ussir !**

**üìß Contact : karim.laurent@gmail.com**
**üìö Guide technique : guide_technique_detaille.pdf**

::: notes
Fin motivante et actionnable.
Rappel du plan progressif.
Donner confiance : c'est accessible !
:::

---

# Merci ! Questions ? üôã

:::::::::::::: {.columns}
::: {.column width="50%"}
## üìö Documentation

- Guide technique complet (PDF)
- Scripts Python pr√™ts √† l'emploi
- Tutoriels vid√©o

## üîó Liens utiles

- ollama.com
- huggingface.co
- reddit.com/r/LocalLLaMA
:::

::: {.column width="50%"}
## üí¨ Support

- Email : karim.laurent@gmail.com

## üéØ Ressources

- Pr√©sentation : presentation_grand_public.pptx
- Guide : guide_technique_detaille.pdf
- Code : github.com/kl-IOS/IA_Locale
:::
::::::::::::::

**N'h√©sitez pas √† poser vos questions !** üòä

::: notes
Slide finale avec contacts et ressources.
Ouverture aux questions.
Ambiance positive et encourageante.
:::
