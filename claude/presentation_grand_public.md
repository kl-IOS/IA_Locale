---
title: "CrÃ©ez votre IA Locale"
subtitle: "Le Guide Complet de A Ã  Z pour les Non-Techniciens"
author: "Guide IA Locale"
date: "Octobre 2025"
theme: "Madrid"
colortheme: "seahorse"
fonttheme: "structurebold"
aspectratio: 169
---

# CrÃ©ez votre IA Locale ğŸš€

**Le Guide Complet de A Ã  Z**

*Pour les non-techniciens*

::: notes
Cette prÃ©sentation s'adresse Ã  un public non-technique souhaitant comprendre et crÃ©er une IA locale.
Le ton est accessible, friendly et encourageant.
DurÃ©e estimÃ©e : 20-30 minutes.
:::

---

# Qu'est-ce qu'une IA locale ? ğŸ¤”

Une IA locale fonctionne **entiÃ¨rement sur votre ordinateur**, sans connexion Internet.

:::::::::::::: {.columns}
::: {.column width="33%"}
## ğŸ”’ ConfidentialitÃ©

Vos donnÃ©es restent **chez vous**

- Aucune transmission externe
- ContrÃ´le total
- ZÃ©ro fuite de donnÃ©es
:::

::: {.column width="33%"}
## ğŸ® ContrÃ´le complet

Vous maÃ®trisez **tout le systÃ¨me**

- Personnalisation totale
- Pas de limitations
- Votre infrastructure
:::

::: {.column width="33%"}
## ğŸ’¸ Sans abonnement

**Pas de coÃ»ts rÃ©currents**

- Investissement unique
- Pas de surprise
- Ã‰conomies long terme
:::
::::::::::::::

::: notes
Insister sur les 3 piliers : confidentialitÃ©, contrÃ´le, Ã©conomies.
Exemples concrets : documents d'entreprise sensibles, donnÃ©es mÃ©dicales, informations financiÃ¨res.
:::

---

# De quoi avez-vous besoin ? ğŸ’»

:::::::::::::: {.columns}
::: {.column width="50%"}
## MatÃ©riel

âœ… **Ordinateur moderne**
- Windows, Mac ou Linux
- 16 Ã  32 Go de RAM
- Carte graphique (idÃ©alement NVIDIA)
- SSD 256 Go minimum

ğŸ’¡ *Pas besoin de super-ordinateur !*
:::

::: {.column width="50%"}
## Logiciels

âœ… **Outils gratuits et open-source**
- Python (langage de programmation)
- Ollama ou LM Studio (IA locale)
- BibliothÃ¨ques spÃ©cialisÃ©es

ğŸ’¡ *Tout est gratuit et tÃ©lÃ©chargeable !*
:::
::::::::::::::

::: notes
Rassurer l'audience : pas besoin de matÃ©riel hors de prix.
Un bon PC gaming ou MacBook Pro rÃ©cent suffit amplement.
Tous les logiciels mentionnÃ©s sont gratuits et open-source.
:::

---

# Les 5 grandes Ã©tapes ğŸ—ºï¸

```mermaid
graph LR
    A[1ï¸âƒ£ DÃ©finir<br/>votre besoin] --> B[2ï¸âƒ£ PrÃ©parer<br/>vos donnÃ©es]
    B --> C[3ï¸âƒ£ Choisir la<br/>bonne mÃ©thode]
    C --> D[4ï¸âƒ£ Installer<br/>et configurer]
    D --> E[5ï¸âƒ£ Tester<br/>et utiliser !]

    style A fill:#5EA8A7,color:#fff
    style B fill:#5EA8A7,color:#fff
    style C fill:#5EA8A7,color:#fff
    style D fill:#5EA8A7,color:#fff
    style E fill:#FE4447,color:#fff
```

::: notes
Vue d'ensemble du processus complet.
Montrer que c'est structurÃ© et progressif.
La derniÃ¨re Ã©tape (test et utilisation) est mise en avant (couleur diffÃ©rente).
:::

---

# Ã‰tape 1 : DÃ©finir votre besoin ğŸ¯

**Posez-vous ces questions :**

:::::::::::::: {.columns}
::: {.column width="33%"}
### â“ Que voulez-vous faire ?

- RÃ©pondre Ã  des questions
- RÃ©sumer des documents
- Analyser du texte
- GÃ©nÃ©rer du contenu
:::

::: {.column width="33%"}
### ğŸ“ Quelles donnÃ©es avez-vous ?

- Documents PDF, Word
- Notes personnelles
- Emails archivÃ©s
- Historique YouTube
:::

::: {.column width="33%"}
### âš¡ Vos contraintes ?

- Vitesse nÃ©cessaire
- Niveau de confidentialitÃ©
- Budget matÃ©riel
- ComplexitÃ© acceptable
:::
::::::::::::::

::: notes
Importance de bien dÃ©finir le besoin avant de se lancer.
Exemples concrets :
- Assistant pour chercher dans sa documentation personnelle
- RÃ©sumeur automatique d'articles de veille
- Chatbot pour rÃ©pondre sur ses notes de cours
:::

---

# Ã‰tape 2 : PrÃ©parer vos donnÃ©es ğŸ“Š

:::::::::::::: {.columns}
::: {.column width="50%"}
## Sources possibles

**ğŸ“„ Documents**
- PDF, Word, PowerPoint
- Fichiers texte

**ğŸ“ Notes**
- Markdown, Notion
- Obsidian, Evernote
:::

::: {.column width="50%"}
## Organisation nÃ©cessaire

**1. Nettoyer**
Supprimer doublons, corriger erreurs

**2. ProtÃ©ger**
Masquer infos personnelles

**3. DÃ©couper**
Diviser longs documents

**4. Enrichir**
Ajouter mÃ©tadonnÃ©es
:::
::::::::::::::

::: notes
Insister sur l'importance de la qualitÃ© des donnÃ©es.
"Garbage in, garbage out" : une IA nourrie de mauvaises donnÃ©es donnera de mauvais rÃ©sultats.
Anonymisation : exemple avec RGPD en entreprise.
:::

---

# Ã‰tape 3 : RAG et Fine-tuning âš–ï¸

:::::::::::::: {.columns}
::: {.column width="50%"}
## RAG ğŸ”ğŸ“
**Recherche + GÃ©nÃ©ration**

âœ… **Avantages**
- Rapide Ã  mettre en place
- IdÃ©al pour documents
- **RecommandÃ© pour dÃ©buter**
- Pas d'entraÃ®nement

ğŸ’¡ **Fonctionnement**
L'IA cherche dans vos documents puis gÃ©nÃ¨re une rÃ©ponse

```mermaid
graph LR
    A[ğŸ“š Documents] --> B[ğŸ”¢ Vecteurs]
    B --> C[ğŸ’¾ Base vectorielle]
    D[â“ Question] --> E[ğŸ” Recherche]
    C --> E
    E --> F[ğŸ¤– IA]
    F --> G[âœ… RÃ©ponse]

    style A fill:#5EA8A7,color:#fff
    style G fill:#FE4447,color:#fff
```
:::

::: {.column width="50%"}
## Fine-tuning ğŸ“
**EntraÃ®nement personnalisÃ©**

âœ… **Avantages**
- Plus de contrÃ´le
- Style personnalisÃ©
- Connaissances intÃ©grÃ©es

âš ï¸ **Mais...**
- **Plus technique**
- NÃ©cessite beaucoup d'exemples
- Temps d'entraÃ®nement

**Ã‰tapes simples du RAG :**

1. Vos documents â†’ vecteurs
2. Recherche passages pertinents
3. IA formule la rÃ©ponse
:::
::::::::::::::

**Notre recommandation : Commencez par RAG !** ğŸ¯

::: notes
RAG est l'approche la plus accessible pour dÃ©buter.
Fine-tuning pour plus tard, quand on a de l'expÃ©rience.
Analogie : RAG = livre ouvert pendant l'exam, Fine-tuning = apprendre par cÅ“ur
:::

---

# Ã‰tape 4 : Installation complÃ¨te ğŸ› ï¸

:::::::::::::: {.columns}
::: {.column width="50%"}
## Outil principal : **Ollama** â­

âœ… **Pourquoi Ollama ?**
- Interface **trÃ¨s simple**
- Installation en 2 minutes
- Windows, Mac, Linux
- Gratuit et open-source

### Installation Ollama

```bash
# Linux / macOS
curl -fsSL ollama.com/install.sh | sh

# Windows
# TÃ©lÃ©charger depuis ollama.com
```

### TÃ©lÃ©charger un modÃ¨le

```bash
ollama pull llama3.1:8b
```
:::

::: {.column width="50%"}
## Python et dÃ©pendances ğŸ

### Installer Python

**Windows**
1. TÃ©lÃ©charger python.org
2. Cocher "Add to PATH" âœ…
3. VÃ©rifier : `python --version`

**Mac / Linux**
```bash
# Mac (Homebrew)
brew install python@3.11

# Linux (Ubuntu/Debian)
sudo apt install python3.11
```

### BibliothÃ¨ques nÃ©cessaires

```bash
# CrÃ©er environnement virtuel
python -m venv mon_ia_locale
source mon_ia_locale/bin/activate

# Installer bibliothÃ¨ques
pip install langchain chromadb \
  sentence-transformers ollama
```
:::
::::::::::::::

::: notes
Ollama est vraiment la solution la plus simple.
Montrer qu'en 2 commandes on peut avoir une IA fonctionnelle.
Tous les outils sont gratuits, insister lÃ -dessus.
:::

---

# VÃ©rification et choix du modÃ¨le âœ…

:::::::::::::: {.columns}
::: {.column width="50%"}
## Test rapide d'installation

```python
import ollama
from langchain_community.embeddings \
  import HuggingFaceEmbeddings

# Test 1 : Ollama
print("Test Ollama...")
response = ollama.chat(
  model='llama3.1:8b',
  messages=[{
    'role': 'user',
    'content': 'Bonjour !'
  }]
)
print(f"âœ… Ollama OK")

# Test 2 : Embeddings
embeddings = HuggingFaceEmbeddings()
test_vec = embeddings.embed_query("Test")
print(f"âœ… Embeddings : {len(test_vec)}D")

print("ğŸ‰ Tout fonctionne !")
```
:::

::: {.column width="50%"}
## Choisir le bon modÃ¨le

| ModÃ¨le | Taille | RAM | QualitÃ© |
|--------|--------|-----|---------|
| **Llama 3.1 8B** | 4.7 GB | 8 GB | â­â­â­â­ |
| **Mistral 7B** | 4.1 GB | 8 GB | â­â­â­â­ |
| **Phi-3 Mini** | 2.3 GB | 4 GB | â­â­â­ |
| **Llama 13B** | 7.4 GB | 16 GB | â­â­â­â­â­ |

**RecommandÃ© dÃ©butant : Llama 3.1 8B**

### Config matÃ©rielle recommandÃ©e

**Budget** (500-800â‚¬) : i5, 16GB RAM, RTX 3060
**Optimal** (1200-1800â‚¬) : i7, 32GB RAM, RTX 4070
**Pro** (3000â‚¬+) : i9, 64GB RAM, RTX 4090
:::
::::::::::::::

::: notes
Script de validation pour rassurer que tout est bien installÃ©.
Tableau clair pour aider au choix du modÃ¨le.
:::

---

# Ã‰tape 5 : CrÃ©er votre systÃ¨me RAG ! ğŸ¬

**Processus en 5 sous-Ã©tapes**

1ï¸âƒ£ Installer Ollama
2ï¸âƒ£ TÃ©lÃ©charger un modÃ¨le (ex: Llama 3.1)
3ï¸âƒ£ Indexer vos documents (Python + Chroma)
4ï¸âƒ£ CrÃ©er systÃ¨me Q&R (LangChain)
5ï¸âƒ£ Tester et affiner !

### Script RAG complet (30 lignes)

```python
from langchain_community.document_loaders import DirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
from langchain_community.llms import Ollama
from langchain.chains import RetrievalQA

# 1. Charger documents
loader = DirectoryLoader("mes_documents/", glob="**/*.txt")
documents = loader.load()

# 2. DÃ©couper en morceaux
text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
chunks = text_splitter.split_documents(documents)

# 3. CrÃ©er embeddings
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2")

# 4. CrÃ©er base vectorielle
vectorstore = Chroma.from_documents(chunks, embeddings)

# 5. Connecter Ollama
llm = Ollama(model="llama3.1:8b")

# 6. CrÃ©er systÃ¨me RAG
qa_chain = RetrievalQA.from_chain_type(
    llm=llm, retriever=vectorstore.as_retriever(search_kwargs={"k": 3})
)

# 7. Poser questions !
reponse = qa_chain.invoke({"query": "Qu'est-ce que le RAG ?"})
print(reponse['result'])
```

::: notes
Processus en 5 Ã©tapes simples et logiques.
Code complet fonctionnel en 30 lignes.
Total : un week-end pour avoir un systÃ¨me fonctionnel.
:::

---

# Exemple concret : Assistant de cours ğŸ¯

**Situation** : 50 PDFs de cours universitaires

### Ã‰tapes

1. CrÃ©er dossier avec vos PDFs
2. Lancer script RAG
3. Attendre 2-5 minutes (indexation)
4. Poser vos questions !

### Questions exemples

```python
qa_chain.invoke({
  "query": "RÃ©sume le chapitre sur les rÃ©seaux de neurones"
})
qa_chain.invoke({
  "query": "DiffÃ©rence entre CNN et RNN ?"
})
```

### RÃ©sultat

âœ… RÃ©ponses **prÃ©cises** basÃ©es sur vos documents
âœ… **Sources citÃ©es** (quel PDF, quelle page)
âœ… Temps de rÃ©ponse : **1-3 secondes**
âœ… Ã‰conomie de temps : **-82%** (45min â†’ 8min)

::: notes
Exemple concret et relatable pour Ã©tudiants.
Montrer la valeur immÃ©diate : gagner du temps dans les rÃ©visions.
:::

---

# ProblÃ¨mes courants & Optimisations ğŸ”§

:::::::::::::: {.columns}
::: {.column width="50%"}
## âŒ ProblÃ¨mes frÃ©quents

**"Ollama not found"**
â†’ RedÃ©marrer terminal ou ajouter au PATH

**"Out of memory"**
â†’ Utiliser modÃ¨le plus petit (Phi-3)
â†’ Fermer autres applications

**RÃ©ponses lentes (>10s)**
â†’ VÃ©rifier GPU : `nvidia-smi`
â†’ Installer CUDA toolkit

**RÃ©ponses imprÃ©cises**
â†’ Nettoyer documents (OCR)
â†’ Ajuster `chunk_size` (300/500/1000)
:::

::: {.column width="50%"}
## ğŸš€ 5 astuces d'optimisation

**1. Choisir le bon modÃ¨le**
- Llama 3.1 8B : Ã©quilibrÃ©
- Mistral 7B : excellent franÃ§ais

**2. Optimiser chunking**
```python
chunk_size=500  # Ã‰quilibrÃ© âœ…
```

**3. Augmenter k (documents)**
```python
search_kwargs={"k": 5}
```

**4. Utiliser le cache**
```python
vectorstore = Chroma(
  persist_directory="./chroma_db"
)
```

**5. Ajuster tempÃ©rature**
```python
# Factuel
temperature=0.1
# CrÃ©atif
temperature=0.7
```
:::
::::::::::::::

::: notes
Anticiper les problÃ¨mes courants pour rassurer.
Solutions concrÃ¨tes et testÃ©es.
:::

---

# Avantages, limites et cas d'usage âš–ï¸

:::::::::::::: {.columns}
::: {.column width="50%"}
## âœ… Avantages

**ConfidentialitÃ© maximale**
- DonnÃ©es sous contrÃ´le
- Aucune fuite

**Pas de frais rÃ©currents**
- Investissement unique
- Pas d'abonnement

**Personnalisation totale**
- AdaptÃ© Ã  vos besoins
- Aucune limite

## âš ï¸ Ã€ considÃ©rer

**Investissement matÃ©riel**
- PC performant : 500-2000â‚¬

**Courbe d'apprentissage**
- Quelques heures/jours

**Maintenance**
- Mises Ã  jour manuelles
:::

::: {.column width="50%"}
## ğŸ’¼ Cas d'usage concrets

**ğŸ¢ Entreprise**
- Documentation interne
- Analyse contrats
- Support client L1

**ğŸ‘¨â€ğŸ“ Ã‰ducation**
- Assistant rÃ©visions
- RÃ©sumÃ© de cours
- Q&A notes de lecture

**ğŸ¥ SantÃ©**
- Dossiers mÃ©dicaux
- Anonymisation donnÃ©es
- Assistant protocoles

**ğŸ”¬ Recherche**
- Analyse littÃ©rature
- Veille scientifique

**Tous bÃ©nÃ©ficient de la confidentialitÃ© !** ğŸ”’
:::
::::::::::::::

**Verdict : Les avantages dÃ©passent les inconvÃ©nients !** ğŸ‰

::: notes
ÃŠtre honnÃªte sur les limites mais positif sur le bilan global.
Comparaison cloud : ChatGPT Plus = 240$/an.
:::

---

# Comparaison Local vs Cloud â˜ï¸

| CritÃ¨re | IA Locale ğŸ  | IA Cloud â˜ï¸ |
|---------|-------------|------------|
| **ConfidentialitÃ©** | âœ… Totale | âŒ Partielle |
| **CoÃ»t mensuel** | âœ… 0â‚¬ | âŒ 20-100â‚¬ |
| **CoÃ»t initial** | âš ï¸ 500-2000â‚¬ | âœ… 0â‚¬ |
| **Performance** | âš ï¸ Selon matÃ©riel | âœ… TrÃ¨s Ã©levÃ©e |
| **Personnalisation** | âœ… Totale | âŒ LimitÃ©e |
| **Hors ligne** | âœ… Oui | âŒ Non |
| **ComplexitÃ©** | âš ï¸ Moyenne | âœ… Simple |

**Quand choisir le local ?**

âœ… DonnÃ©es sensibles (entreprise, santÃ©, finance)
âœ… Usage intensif (amortissement rapide)
âœ… Besoin de personnalisation
âœ… Pas de connexion Internet fiable

::: notes
Tableau comparatif honnÃªte.
Calcul d'amortissement : ChatGPT Plus Ã  20$/mois = 720$ sur 3 ans.
Un PC avec GPU RTX 3060 Ã  1000â‚¬ est amorti en moins de 2 ans.
:::

---

# Ressources et prochaines Ã©tapes ğŸ“š

:::::::::::::: {.columns}
::: {.column width="50%"}
## Documentation & Tutoriels

ğŸ“– **Guide technique dÃ©taillÃ©** (PDF)
ğŸ¥ **Tutoriels vidÃ©o** : Ollama, LangChain
ğŸ’» **Code d'exemple** : scripts Python

## CommunautÃ©s

- **Reddit r/LocalLLaMA** : entraide
- **Discord LangChain** : support technique
- **Hugging Face Forums** : questions modÃ¨les

## Outils

- **Ollama** : ollama.com
- **LM Studio** : lmstudio.ai
- **Hugging Face** : huggingface.co
:::

::: {.column width="50%"}
## ğŸš€ Prochaines Ã©tapes

**Week-end 1**
1. Installer Ollama (10 min)
2. TÃ©lÃ©charger Llama 3.1 (15 min)
3. Tester en ligne de commande (30 min)

**Semaine 1**
4. Installer Python (1h)
5. PrÃ©parer donnÃ©es (2-4h)
6. CrÃ©er premier RAG (3-5h)

**Roadmap Mois 1**
- S1 : Installation et tests
- S2 : RAG basique fonctionnel
- S3 : Optimisation
- S4 : Production

ğŸ“– **Consultez le guide technique !**
:::
::::::::::::::

::: notes
Fournir ressources concrÃ¨tes pour continuer.
CommunautÃ© active et bienveillante.
Planning rÃ©aliste : week-end pour dÃ©marrer, 1 mois pour systÃ¨me robuste.
:::

---

# FAQ & Glossaire ğŸ“–â“

:::::::::::::: {.columns}
::: {.column width="50%"}
## Questions FrÃ©quentes

**Quel budget prÃ©voir ?**
Minimum 500â‚¬, optimal 1500-2000â‚¬

**Temps pour Ãªtre opÃ©rationnel ?**
Week-end pour test, 1-2 semaines complet

**Faut-il Ãªtre dÃ©veloppeur ?**
Non, bases Python suffisent (quelques jours)

**Quelle taille de modÃ¨le ?**
DÃ©butant : 7-8B (Llama, Mistral)
AvancÃ© : 13B avec bon GPU

**Plusieurs modÃ¨les possibles ?**
Oui ! Ollama permet de basculer facilement

**DonnÃ©es vraiment en local ?**
Oui, 100% local avec Ollama/llama.cpp
:::

::: {.column width="50%"}
## Glossaire

**IA Locale**
IA sur votre ordinateur sans Internet

**RAG**
Recherche dans documents pour rÃ©pondre

**LLM**
Grand ModÃ¨le de Langage, "cerveau" de l'IA

**Fine-tuning**
EntraÃ®ner l'IA pour style spÃ©cifique

**Embeddings**
ReprÃ©sentation mathÃ©matique du texte

**Ollama**
Outil simple pour IA locales

**Chunking**
DÃ©couper documents en morceaux

**Anonymisation**
Supprimer infos personnelles
:::
::::::::::::::

::: notes
RÃ©ponses concises aux questions frÃ©quentes.
DÃ©finitions vulgarisÃ©es, accessibles Ã  tous.
:::

---

# Conclusion : Lancez-vous ! ğŸ‰

## Ce que vous avez appris

âœ… Qu'est-ce qu'une IA locale et pourquoi c'est utile
âœ… Le matÃ©riel et les logiciels nÃ©cessaires
âœ… Les 5 grandes Ã©tapes pour crÃ©er votre IA
âœ… La diffÃ©rence entre RAG et fine-tuning
âœ… Comment dÃ©marrer concrÃ¨tement

## Votre plan d'action

1. **Ce soir** : tÃ©lÃ©charger Ollama et tester un modÃ¨le
2. **Ce week-end** : prÃ©parer vos premiÃ¨res donnÃ©es
3. **Semaine prochaine** : crÃ©er votre premier systÃ¨me RAG
4. **Dans 1 mois** : systÃ¨me complet en production !

**ğŸš€ Vous avez tout ce qu'il faut pour rÃ©ussir !**

**ğŸ“§ Contact : karim.laurent@gmail.com**
**ğŸ“š Guide technique : guide_technique_detaille.pdf**

::: notes
Fin motivante et actionnable.
Rappel du plan progressif.
Donner confiance : c'est accessible !
:::

---

# Merci ! Questions ? ğŸ™‹

:::::::::::::: {.columns}
::: {.column width="50%"}
## ğŸ“š Documentation

- Guide technique complet (PDF)
- Scripts Python prÃªts Ã  l'emploi
- Tutoriels vidÃ©o

## ğŸ”— Liens utiles

- ollama.com
- huggingface.co
- reddit.com/r/LocalLLaMA
:::

::: {.column width="50%"}
## ğŸ’¬ Support

- Email : karim.laurent@gmail.com

## ğŸ¯ Ressources

- PrÃ©sentation : presentation_grand_public.pptx
- Guide : guide_technique_detaille.pdf
- Code : github.com/kl-IOS/IA_Locale
:::
::::::::::::::

**N'hÃ©sitez pas Ã  poser vos questions !** ğŸ˜Š

::: notes
Slide finale avec contacts et ressources.
Ouverture aux questions.
Ambiance positive et encourageante.
:::
