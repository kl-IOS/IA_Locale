# Guide d'Installation Ollama - Pas √† Pas

**Pour d√©butants - Avec captures d'√©cran et explications d√©taill√©es**

---

## üìã Table des mati√®res

1. [Installation d'Ollama](#1-installation-dollama)
   - Windows
   - macOS
   - Linux
2. [Premiers pas avec Ollama](#2-premiers-pas-avec-ollama)
3. [T√©l√©charger et utiliser un mod√®le](#3-t√©l√©charger-et-utiliser-un-mod√®le)
4. [Exemples d'utilisation concr√®te](#4-exemples-dutilisation-concr√®te)
5. [Installation sur plusieurs PC](#5-installation-sur-plusieurs-pc)
6. [Comprendre l'indexation (expliqu√© simplement)](#6-comprendre-lindexation)
7. [Probl√®mes courants et solutions](#7-probl√®mes-courants-et-solutions)

---

## 1. Installation d'Ollama

### ü™ü Windows (Windows 10/11)

**√âtape 1 : T√©l√©charger Ollama**

1. Ouvrez votre navigateur web
2. Allez sur **[https://ollama.com](https://ollama.com)**
3. Cliquez sur le bouton **"Download for Windows"**

> üì∏ *Capture d'√©cran recommand√©e : Page d'accueil ollama.com avec le bouton de t√©l√©chargement*

**√âtape 2 : Installer Ollama**

1. Ouvrez le fichier t√©l√©charg√© `OllamaSetup.exe`
2. Windows peut afficher un avertissement de s√©curit√© ‚Üí Cliquez sur **"Ex√©cuter quand m√™me"**
3. Suivez l'assistant d'installation (cliquez sur "Suivant" ‚Üí "Installer")
4. L'installation prend environ **30 secondes**
5. √Ä la fin, cliquez sur **"Terminer"**

> üì∏ *Capture d'√©cran recommand√©e : Fen√™tre d'installation Windows*

**√âtape 3 : V√©rifier l'installation**

1. Appuyez sur `Windows + R`
2. Tapez `cmd` et appuyez sur Entr√©e
3. Dans la fen√™tre noire (invite de commandes), tapez :
   ```bash
   ollama --version
   ```
4. Vous devriez voir : `ollama version 0.x.x`

‚úÖ **C'est install√© !**

---

### üçé macOS (Mac)

**√âtape 1 : T√©l√©charger Ollama**

1. Ouvrez Safari ou Chrome
2. Allez sur **[https://ollama.com](https://ollama.com)**
3. Cliquez sur **"Download for macOS"**
4. Un fichier `.zip` sera t√©l√©charg√©

> üì∏ *Capture d'√©cran recommand√©e : Page d'accueil ollama.com*

**√âtape 2 : Installer Ollama**

1. Ouvrez le fichier `.zip` t√©l√©charg√© (double-clic)
2. Glissez l'application **Ollama** dans votre dossier **Applications**
3. Ouvrez le dossier **Applications**
4. Double-cliquez sur **Ollama**
5. macOS peut afficher "Impossible d'ouvrir car provient d'un d√©veloppeur non identifi√©"
   - Allez dans **Pr√©f√©rences Syst√®me** ‚Üí **S√©curit√© et confidentialit√©**
   - Cliquez sur **"Ouvrir quand m√™me"**

> üì∏ *Capture d'√©cran recommand√©e : Fen√™tre de s√©curit√© macOS*

**√âtape 3 : V√©rifier l'installation**

1. Ouvrez **Terminal** (Cmd + Espace ‚Üí tapez "Terminal")
2. Tapez :
   ```bash
   ollama --version
   ```
3. Vous devriez voir : `ollama version 0.x.x`

‚úÖ **C'est install√© !**

---

### üêß Linux (Ubuntu/Debian)

**√âtape 1 : Installation en une ligne**

Ouvrez un Terminal et ex√©cutez :

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

Cette commande :
- T√©l√©charge le script d'installation
- Installe Ollama automatiquement
- Configure tout pour vous

**Attente : environ 1-2 minutes**

**√âtape 2 : V√©rifier l'installation**

```bash
ollama --version
```

Vous devriez voir : `ollama version 0.x.x`

‚úÖ **C'est install√© !**

---

## 2. Premiers pas avec Ollama

### üéØ Les 5 commandes essentielles

Voici les **seules commandes** que vous devez conna√Ætre :

#### 1Ô∏è‚É£ T√©l√©charger un mod√®le

```bash
ollama pull llama3.1:8b
```

**Explication** :
- `pull` = t√©l√©charger
- `llama3.1:8b` = nom du mod√®le (8 milliards de param√®tres)

**Temps** : 5-10 minutes selon votre connexion

---

#### 2Ô∏è‚É£ Lancer une conversation avec l'IA

```bash
ollama run llama3.1:8b
```

**R√©sultat** : Une interface de chat s'ouvre

```
>>> Bonjour !
Bonjour ! Comment puis-je vous aider aujourd'hui ?

>>> Explique-moi ce qu'est une IA locale
Une IA locale est...
```

Pour **quitter** : tapez `/bye` ou `Ctrl+D`

---

#### 3Ô∏è‚É£ Lister les mod√®les install√©s

```bash
ollama list
```

**R√©sultat** :
```
NAME                ID              SIZE    MODIFIED
llama3.1:8b        a1b2c3d4        4.7GB   2 hours ago
mistral:7b         e5f6g7h8        4.1GB   1 day ago
```

---

#### 4Ô∏è‚É£ Supprimer un mod√®le

```bash
ollama rm llama3.1:8b
```

Utile pour lib√©rer de l'espace disque.

---

#### 5Ô∏è‚É£ Voir les mod√®les disponibles

Allez sur **[https://ollama.com/library](https://ollama.com/library)**

Liste compl√®te de tous les mod√®les t√©l√©chargeables.

---

## 3. T√©l√©charger et utiliser un mod√®le

### üß† Quel mod√®le choisir ?

**Pour d√©buter, nous recommandons :**

| Mod√®le | Commande | Taille | RAM n√©cessaire | Qualit√© |
|--------|----------|--------|----------------|---------|
| **Llama 3.1 8B** ‚≠ê | `ollama pull llama3.1:8b` | 4.7 GB | 8 GB | ‚≠ê‚≠ê‚≠ê‚≠ê Excellent |
| **Mistral 7B** üá´üá∑ | `ollama pull mistral:7b` | 4.1 GB | 8 GB | ‚≠ê‚≠ê‚≠ê‚≠ê Parfait fran√ßais |
| **Phi-3 Mini** üíª | `ollama pull phi3:mini` | 2.3 GB | 4 GB | ‚≠ê‚≠ê‚≠ê PC modestes |

**Notre conseil** : Commencez par **Llama 3.1 8B** ou **Mistral 7B**

---

### üì• T√©l√©charger votre premier mod√®le

**√âtape par √©tape :**

1. Ouvrez votre **Terminal** (ou **Invite de commandes** sur Windows)

2. Tapez et appuyez sur Entr√©e :
   ```bash
   ollama pull llama3.1:8b
   ```

3. Vous verrez :
   ```
   pulling manifest
   pulling 8934d96d3f08... 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 4.7 GB
   pulling 8c17c2ebb0ea... 100% ‚ñï‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè 7.0 KB
   verifying sha256 digest
   writing manifest
   success
   ```

4. **Attente** : 5-10 minutes selon votre connexion Internet

‚úÖ **Mod√®le t√©l√©charg√© et pr√™t √† l'emploi !**

---

### üí¨ Lancer une conversation

```bash
ollama run llama3.1:8b
```

**Interface interactive :**

```
>>> Bonjour, peux-tu te pr√©senter ?
Bonjour ! Je suis un assistant IA fonctionnant localement sur votre ordinateur.
Je peux vous aider avec diverses t√¢ches : r√©pondre √† des questions, r√©sumer des
textes, √©crire du contenu, etc. Comment puis-je vous aider aujourd'hui ?

>>> R√©sume-moi ce qu'est le RAG en 3 lignes
Le RAG (Retrieval Augmented Generation) est une technique qui combine :
1. La recherche d'informations pertinentes dans une base de documents
2. L'utilisation d'un mod√®le d'IA pour g√©n√©rer une r√©ponse bas√©e sur ces documents
3. Le tout permet d'obtenir des r√©ponses pr√©cises et sourc√©es, sans hallucinations.
```

**Pour quitter** : tapez `/bye`

---

## 4. Exemples d'utilisation concr√®te

### Exemple 1 : R√©sumer un texte

```bash
ollama run llama3.1:8b
```

```
>>> R√©sume ce texte en 3 points cl√©s :
L'intelligence artificielle locale pr√©sente de nombreux avantages par rapport
aux solutions cloud. Elle garantit la confidentialit√© totale des donn√©es car
rien ne quitte votre ordinateur. Elle permet aussi de r√©aliser des √©conomies
substantielles en √©vitant les abonnements mensuels co√ªteux. Enfin, elle offre
une personnalisation compl√®te selon vos besoins sp√©cifiques.

Voici les 3 points cl√©s :
1. Confidentialit√© totale - aucune donn√©e ne quitte votre ordinateur
2. √âconomies importantes - pas d'abonnement mensuel
3. Personnalisation compl√®te selon vos besoins
```

---

### Exemple 2 : Poser des questions sur un sujet

```
>>> Explique-moi la diff√©rence entre RAM et stockage SSD

La RAM (Random Access Memory) et le stockage SSD ont des r√¥les diff√©rents :

RAM :
- M√©moire volatile (donn√©es effac√©es √† l'extinction)
- Tr√®s rapide (acc√®s en nanosecondes)
- Utilis√©e pour les programmes en cours d'ex√©cution
- Plus ch√®re par Go

SSD :
- Stockage permanent (donn√©es conserv√©es)
- Rapide mais moins que la RAM
- Utilis√© pour stocker fichiers et programmes
- Moins cher par Go

Analogie : La RAM est comme votre bureau de travail (rapide mais temporaire),
le SSD est comme votre armoire de rangement (permanent mais un peu plus lent).
```

---

### Exemple 3 : G√©n√©rer du contenu

```
>>> √âcris-moi un email professionnel pour demander un rendez-vous

Objet : Demande de rendez-vous

Bonjour [Nom],

J'esp√®re que ce message vous trouve en bonne forme.

Je souhaiterais solliciter un rendez-vous avec vous afin de discuter de
[sujet pr√©cis]. Je pense que nos √©changes pourraient √™tre mutuellement
b√©n√©fiques concernant [contexte].

Seriez-vous disponible la semaine prochaine pour un entretien de 30 minutes ?
Je m'adapterai volontiers √† vos disponibilit√©s.

Dans l'attente de votre retour,
Cordialement,
[Votre nom]
```

---

## 5. Installation sur plusieurs PC

### üñ•Ô∏è Question : Puis-je installer Ollama sur plusieurs ordinateurs ?

**R√©ponse : OUI ! Et c'est m√™me recommand√©.**

Chaque PC aura sa **propre IA locale ind√©pendante**.

---

### üì¶ M√©thode 1 : Installation manuelle (recommand√©e pour 2-3 PC)

**Sur chaque PC :**

1. T√©l√©chargez Ollama depuis [ollama.com](https://ollama.com)
2. Installez-le (2 minutes)
3. T√©l√©chargez les mod√®les souhait√©s :
   ```bash
   ollama pull llama3.1:8b
   ollama pull mistral:7b
   ```

**Avantages** :
- ‚úÖ Simple et s√ªr
- ‚úÖ Chaque PC est ind√©pendant
- ‚úÖ Pas de comp√©tences techniques requises

**Temps** : 10-15 minutes par PC

---

### üöÄ M√©thode 2 : Script d'installation automatique (Windows)

**Pour installer sur 5+ PC de mani√®re automatis√©e**

Cr√©ez un fichier `install_ollama.bat` :

```batch
@echo off
echo ========================================
echo Installation automatique d'Ollama
echo ========================================

REM T√©l√©charger Ollama
echo T√©l√©chargement d'Ollama...
curl -L https://ollama.com/download/OllamaSetup.exe -o %TEMP%\OllamaSetup.exe

REM Installer Ollama en mode silencieux
echo Installation en cours...
%TEMP%\OllamaSetup.exe /S

REM Attendre la fin de l'installation
timeout /t 10

REM T√©l√©charger les mod√®les
echo T√©l√©chargement des mod√®les IA...
ollama pull llama3.1:8b
ollama pull mistral:7b

echo ========================================
echo Installation termin√©e avec succ√®s !
echo ========================================
pause
```

**Utilisation** :
1. Copiez ce fichier sur une cl√© USB
2. Sur chaque PC : double-cliquez sur `install_ollama.bat`
3. Attendez 15-20 minutes (t√©l√©chargement + installation)

---

### üêß M√©thode 3 : Script pour Linux

Cr√©ez un fichier `install_ollama.sh` :

```bash
#!/bin/bash

echo "========================================"
echo "Installation automatique d'Ollama"
echo "========================================"

# Installation d'Ollama
echo "Installation d'Ollama..."
curl -fsSL https://ollama.com/install.sh | sh

# T√©l√©chargement des mod√®les
echo "T√©l√©chargement des mod√®les..."
ollama pull llama3.1:8b
ollama pull mistral:7b

echo "========================================"
echo "Installation termin√©e avec succ√®s !"
echo "========================================"
```

**Utilisation** :

```bash
chmod +x install_ollama.sh
./install_ollama.sh
```

---

### üîÑ Synchroniser les mod√®les entre PC (optionnel)

**Probl√®me** : Les mod√®les sont gros (4-7 GB), les t√©l√©charger 10 fois est long.

**Solution** : T√©l√©charger une fois, copier sur les autres PC.

**O√π se trouvent les mod√®les ?**

- **Windows** : `C:\Users\VotreNom\.ollama\models`
- **macOS** : `~/.ollama/models`
- **Linux** : `~/.ollama/models`

**Proc√©dure** :

1. Sur le PC 1 : t√©l√©chargez tous les mod√®les
2. Copiez le dossier `.ollama/models` sur une cl√© USB
3. Sur les autres PC :
   - Installez Ollama (sans t√©l√©charger de mod√®les)
   - Remplacez le dossier `.ollama/models` par celui de la cl√© USB

**Gain de temps** : T√©l√©chargement 1 fois au lieu de N fois !

---

## 6. Comprendre l'indexation

### ü§î C'est quoi l'indexation exactement ?

**Explication tr√®s simple :**

Imaginez que vous avez 50 livres et qu'on vous demande : *"O√π est-il parl√© de recettes de p√¢tes ?"*

**Sans index** : Vous devez lire les 50 livres en entier (des heures !)

**Avec index** : Vous consultez l'index de chaque livre, qui dit :
- Livre 3 : pages 45, 78, 120
- Livre 12 : pages 23, 56

Vous allez **directement** aux bonnes pages ! (quelques minutes)

---

### üìá L'indexation pour l'IA = cr√©er un index

**Processus :**

1. **Vos documents** (PDFs, Word, textes)
   - Exemple : 50 PDFs de cours universitaires

2. **D√©coupage en morceaux** (chunks)
   - Chaque PDF est d√©coup√© en petits passages de ~500 mots
   - Exemple : PDF de 10 pages ‚Üí 20 morceaux

3. **Transformation en nombres** (embeddings/vecteurs)
   - Chaque morceau est converti en une s√©rie de nombres
   - Ces nombres repr√©sentent le "sens" du texte
   - Exemple : "recette de p√¢tes" ‚Üí `[0.2, -0.5, 0.8, ...]` (768 nombres)

4. **Stockage dans une base de donn√©es** (vectorstore)
   - Tous les morceaux num√©rot√©s sont rang√©s
   - Comme un gros index de biblioth√®que

---

### üîç Comment √ßa marche quand vous posez une question ?

**Vous demandez** : *"C'est quoi un r√©seau de neurones ?"*

**√âtapes automatiques :**

1. **Votre question est transform√©e en nombres**
   - "r√©seau de neurones" ‚Üí `[0.3, -0.4, 0.7, ...]`

2. **L'IA cherche dans l'index**
   - Elle compare vos nombres avec tous les morceaux index√©s
   - Elle trouve les 3-5 morceaux les plus proches (similaires)

3. **L'IA lit les passages pertinents**
   - Passage 1 : "Un r√©seau de neurones est..."
   - Passage 2 : "Les r√©seaux de neurones se composent de..."

4. **L'IA formule une r√©ponse**
   - Elle combine les informations trouv√©es
   - Elle g√©n√®re une r√©ponse claire et pr√©cise

**R√©sultat** : R√©ponse bas√©e sur **vos documents**, pas invent√©e !

---

### ‚è±Ô∏è Quand fait-on l'indexation ?

**Une seule fois au d√©but !**

- Vous indexez vos 50 PDFs : **une fois** (2-5 minutes)
- Ensuite, vous posez 1000 questions : **instantan√©** (1-3 secondes par r√©ponse)

**C'est comme :**
- Cr√©er l'index d'un livre : long (une fois)
- Consulter l'index : rapide (√† chaque fois)

---

### üõ†Ô∏è Comment indexer vos documents ?

**Outils qui font tout automatiquement :**

1. **AnythingLLM** ([useanything.com](https://useanything.com))
   - Interface graphique (pas de code)
   - Glisser-d√©poser vos PDFs
   - Indexation automatique

2. **Langflow** ([langflow.org](https://www.langflow.org))
   - Interface visuelle
   - Connexion facile √† Ollama

3. **Open WebUI** ([github.com/open-webui](https://github.com/open-webui/open-webui))
   - Interface type ChatGPT
   - Upload de documents
   - Indexation en 1 clic

**Avec ces outils : pas besoin de coder !**

---

### üìä Exemple concret d'indexation

**Situation** : 50 PDFs de cours (environ 2000 pages)

**Processus avec AnythingLLM** :

1. **T√©l√©charger AnythingLLM** (5 min)
2. **Connecter √† Ollama** (1 min)
3. **Importer vos PDFs** (glisser-d√©poser, 2 min)
4. **Lancer l'indexation** (cliquer sur "Index", attendre 3-5 min)
5. **C'est pr√™t !** Posez vos questions

**Temps total : 10-15 minutes**

**Ensuite** :
- Question 1 : *"R√©sume le chapitre 3"* ‚Üí R√©ponse en 2 secondes ‚úÖ
- Question 2 : *"Diff√©rence entre CNN et RNN ?"* ‚Üí R√©ponse en 3 secondes ‚úÖ

---

## 7. Probl√®mes courants et solutions

### ‚ùå Probl√®me 1 : "ollama: command not found"

**Sur Windows :**
1. Red√©marrez l'Invite de commandes
2. Si √ßa ne marche toujours pas :
   - Cherchez "Modifier les variables d'environnement syst√®me"
   - Ajoutez `C:\Program Files\Ollama` au PATH

**Sur Mac/Linux :**
```bash
# Ajoutez √† votre ~/.bashrc ou ~/.zshrc
export PATH=$PATH:/usr/local/bin
```

Puis red√©marrez le Terminal.

---

### ‚ùå Probl√®me 2 : "Out of memory"

**Causes** : Votre PC manque de RAM pour le mod√®le choisi.

**Solutions** :

1. **Utilisez un mod√®le plus petit**
   ```bash
   ollama pull phi3:mini  # Seulement 2.3 GB
   ```

2. **Fermez les autres applications**
   - Navigateur web
   - Applications lourdes

3. **Ajoutez de la RAM** (solution √† long terme)
   - 8 GB ‚Üí 16 GB pour confort
   - 16 GB ‚Üí 32 GB pour mod√®les avanc√©s

---

### ‚ùå Probl√®me 3 : T√©l√©chargement tr√®s lent

**Causes** : Connexion Internet lente ou serveurs surcharg√©s.

**Solutions** :

1. **R√©essayez plus tard** (le soir, moins de trafic)

2. **T√©l√©chargez depuis un autre r√©seau**
   - WiFi au lieu d'Ethernet (ou inverse)
   - Hotspot mobile

3. **V√©rifiez votre connexion**
   ```bash
   # Test de vitesse
   speedtest-cli
   ```

---

### ‚ùå Probl√®me 4 : R√©ponses lentes (>10 secondes)

**Causes** : Pas d'acc√©l√©ration GPU ou CPU trop lent.

**Diagnostics** :

**Sur Windows/Linux avec NVIDIA :**
```bash
nvidia-smi
```

Si √ßa affiche votre carte graphique ‚Üí OK
Si erreur ‚Üí GPU pas d√©tect√©

**Solutions** :

1. **Installer les drivers NVIDIA** ([nvidia.com/drivers](https://www.nvidia.com/drivers))

2. **Installer CUDA Toolkit**
   - [developer.nvidia.com/cuda-downloads](https://developer.nvidia.com/cuda-downloads)

3. **Utiliser un mod√®le plus petit**
   - Phi-3 Mini au lieu de Llama 13B

---

### ‚ùå Probl√®me 5 : R√©ponses impr√©cises ou "hallucinations"

**Causes** : Le mod√®le invente des r√©ponses.

**Solutions** :

1. **Utilisez le RAG !**
   - Avec RAG : r√©ponses bas√©es sur vos documents (pr√©cises)
   - Sans RAG : le mod√®le devine (impr√©cis)

2. **Soyez plus pr√©cis dans vos questions**
   - ‚ùå Mauvais : "Explique-moi √ßa"
   - ‚úÖ Bon : "Explique-moi la diff√©rence entre RAG et fine-tuning en 3 points"

3. **Ajustez la temp√©rature** (pour utilisateurs avanc√©s)
   ```bash
   ollama run llama3.1:8b --temperature 0.1
   ```
   - 0.1 = tr√®s factuel, peu cr√©atif
   - 0.7 = √©quilibr√©
   - 1.0 = tr√®s cr√©atif, peut inventer

---

## üéì R√©capitulatif : Vos prochaines √©tapes

**Vous savez maintenant :**

‚úÖ Installer Ollama sur Windows, Mac ou Linux
‚úÖ T√©l√©charger et utiliser un mod√®le d'IA
‚úÖ Les 5 commandes essentielles
‚úÖ Installer Ollama sur plusieurs PC (avec ou sans scripts)
‚úÖ Ce qu'est l'indexation et comment √ßa marche
‚úÖ R√©soudre les probl√®mes courants

**Plan d'action imm√©diat :**

1. **Installez Ollama** (10 min)
2. **T√©l√©chargez Llama 3.1 8B** (10 min)
3. **Testez avec quelques questions** (30 min)
4. **Explorez AnythingLLM pour l'indexation** (1h)
5. **Indexez vos propres documents** (1h)

**Dans 2-3 heures, vous aurez une IA locale fonctionnelle ! üéâ**

---

## üìö Ressources compl√©mentaires

**Documentation officielle :**
- [Ollama Documentation](https://github.com/ollama/ollama/blob/main/README.md)
- [Liste des mod√®les](https://ollama.com/library)

**Outils graphiques (pas de code) :**
- [AnythingLLM](https://useanything.com) - Interface compl√®te
- [Open WebUI](https://github.com/open-webui/open-webui) - Interface type ChatGPT
- [Langflow](https://www.langflow.org) - Builder visuel

**Communaut√©s d'entraide :**
- Reddit : [r/LocalLLaMA](https://reddit.com/r/LocalLLaMA)
- Discord : LangChain, Ollama
- Hugging Face Forums

**Contact :**
- Email : karim.laurent@gmail.com

---

**Bonne chance dans votre aventure avec l'IA locale ! üöÄ**
